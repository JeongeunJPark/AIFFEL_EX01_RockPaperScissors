{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration 노드 1. 인공지능과 가위바위보 하기\n",
    "\n",
    "## 이 노드의 루브릭\n",
    "1. 이미지 분류기 모델이 성공적으로 만들어졌는가? -> \"트레이닝이 정상적으로 수행되었음\"\n",
    "2. 오버피팅을 극복하기 위한 적절한 시도가 있었는가? -> \"데이터셋의 다양성, 정규화 시도 등이 적절하였음\"\n",
    "3. 분류모델의 test accuracy가 기준 이상 높게 나왔는가? -> \"60% 이상 도달하였음\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이 루브릭을 바탕으로, 가위바위보를 인식하는 인공지능 모델을 학습시켜 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비 과정!\n",
    "\n",
    "* 좋은 데이터가 좋은 결과를 낳는다. 다양한 각도의 가위/바위/보 사진을 수집하기\n",
    "* 다양한 각도에서 가위/바위/보 사진을 찍고 다른 분들의 데이터도 다운로드받았다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 가위, 바위, 보를 다양한 각도에서 찍어 여러 사람의 데이터를 받더라도 판별할 수 있게끔 준비하였다.\n",
    "> ![다양한 각도를 준비](./PostingPic/screen_long.png)\n",
    "> ![긴 버전의 가위바위](./PostingPic/screen_short.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 데이터 준비 : 리사이징 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리사이징 완료\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# For문으로 한번에 리사이징\n",
    "# ModelPic 폴더 아래의 /Rock, /Paper, /Scissor 아래에 가위바위보 사진이 라벨별로 들어가있으므로, \n",
    "# 한번에 리사이징할 수 있도록 코드를 변경한다\n",
    "image_directory = os.getenv(\"HOME\")+\"/SUBMIT_MISSION_GIT/ex1_RPC/ModelPic\"\n",
    "path_pool = \"/Rock\", \"/Scissor\", \"/Paper\"\n",
    "\n",
    "target_size=(28, 28)\n",
    "\n",
    "for path in path_pool:\n",
    "    images=glob.glob(image_directory + path + \"/*.jpg\")\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size, Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(\"리사이징 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 1,200개의 데이터 불러와서 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 전에 데이터를 넣고, 잘 불러지는지 확인한다\n",
      "로드된 학습데이터의 이미지 개수는 1200 개 입니다\n",
      "x_train_ (1200, 28, 28, 3)\n",
      "y_train_ (1200,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_data(img_path, number_data):\n",
    "    # 가위는 0, 바위는 1, 보는 2\n",
    "    #numberOfData = 1200 #가위바위보 각 100개씩 X 3라벨 X (내 데이터 + 다른 3분의 데이터)\n",
    "    numberOfData = number_data\n",
    "    imageSize = 28\n",
    "    color = 3\n",
    "    \n",
    "    imgs=np.zeros(numberOfData * imageSize * imageSize * color, dtype=np.int32).reshape(numberOfData, imageSize, imageSize, color)\n",
    "    labels=np.zeros(numberOfData, dtype=np.int32)\n",
    "    \n",
    "    index=0\n",
    "    \n",
    "    for file in glob.iglob(img_path+'/Rock/*.jpg'):\n",
    "        img=np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[index,:,:,:]=img\n",
    "        labels[index]=0\n",
    "        index=index+1\n",
    "    \n",
    "    for file in glob.iglob(img_path+'/Paper/*.jpg'):\n",
    "        img=np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[index,:,:,:]=img\n",
    "        labels[index]=1\n",
    "        index=index+1\n",
    "    \n",
    "    for file in glob.iglob(img_path+'/Scissor/*.jpg'):\n",
    "        img=np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[index,:,:,:]=img\n",
    "        labels[index]=2\n",
    "        index=index+1\n",
    "    \n",
    "    print(\"로드된 학습데이터의 이미지 개수는\", index , \"개 입니다\")\n",
    "    return imgs,labels\n",
    "\n",
    "\n",
    "print(\"학습 전에 데이터를 넣고, 잘 불러지는지 확인한다\")\n",
    "image_dir_path = os.getenv(\"HOME\")+ \"/SUBMIT_MISSION_GIT/ex1_RPC/ModelPic\"\n",
    "(x_train, y_train) = load_data(image_dir_path, 1200)\n",
    "\n",
    "x_train_norm = x_train/255.0\n",
    "\n",
    "print(\"x_train_\",format(x_train.shape))\n",
    "print(\"y_train_\",format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확인 차 0에서 1999까지의 자료 중 아무거나 하나 출력해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨은? 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1199])\n",
    "print('라벨은?' , y_train[1199])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 학습 및 학습 결과 확인 과정!\n",
    "\n",
    "### 2-1. 딥러닝 네트워크 설계하고, 학습시키기\n",
    "    * 이전에 손글씨 분류를 수행했던 Sequential 모델과 동일한 설정으로 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0843 - accuracy: 0.4233\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0078 - accuracy: 0.5642\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8551 - accuracy: 0.6517\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.7700\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.8350\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8867\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.9125\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.9225\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9467\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe2ad864d90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 설계는 이전에 손글씨에서 적용한 Sequential 모델과 동일하다.\n",
    "# 확실히, 이전 손글씨 수행을 통해 이 딥러닝 네트워크가 7개의 레이어로 이루어져 있으며\n",
    "# 각각의 인자가 무엇을 의미하는지 알고 나니 한결 이해하기가 쉽다!\n",
    "\n",
    "RPC=keras.models.Sequential()\n",
    "RPC.add(keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28,28,3)))\n",
    "RPC.add(keras.layers.MaxPool2D(2,2))\n",
    "RPC.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "RPC.add(keras.layers.MaxPooling2D((2,2)))\n",
    "RPC.add(keras.layers.Flatten())\n",
    "RPC.add(keras.layers.Dense(32, activation='relu'))\n",
    "RPC.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "RPC.summary()\n",
    "\n",
    "\n",
    "# 이 딥러닝 모델에 투입할 학습 데이터를 reshaping\n",
    "x_train_reshaped=x_train_norm.reshape(-1, 28, 28,3)  \n",
    "\n",
    "RPC.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "RPC.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델의 __정확도는 0.9617(epoch=10일 때) 가 나왔다!__ 나쁘지 않은걸.\n",
    "\n",
    "__하지만 다른 사람의 데이터로 테스트를 해본다면 어떨까?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Test set으로 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 학습데이터의 이미지 개수는 300 개 입니다\n",
      "After Reshape - x_test_reshaped shape: (300, 28, 28, 3)\n",
      "10/10 - 2s - loss: 2.3613 - accuracy: 0.3600\n",
      "test_loss: 2.3613178730010986 \n",
      "test_accuracy: 0.36000001430511475\n"
     ]
    }
   ],
   "source": [
    "#테스트 셋을 통해 이 모델의 정확도를 평가해보자.\n",
    "\n",
    "test_image_path=os.getenv(\"HOME\") + \"/SUBMIT_MISSION_GIT/ex1_RPC/ModelPic/train_dataset_total/data1\"\n",
    "\n",
    "(x_test, y_test)=load_data(test_image_path,300)\n",
    "x_test_norm=x_test/255.0\n",
    "\n",
    "x_test_reshaped=x_test_norm.reshape(-1, 28, 28,3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))\n",
    "\n",
    "test_loss, test_accuracy = RPC.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처참한 결과가 나왔다. 학습된 데이터셋에서는 정확도가 0.96로 높은 수치를 보였지만, 지금은 0.36 밖에 되지 않는다.\n",
    "__이를 극복하기 위해 어떤 방법을 취해야 할까?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정확도를 높이기 위한 모델 보완 시도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. 원래 성적 올리는 데는 양치기가 짱이다.\n",
    "     * 그래서 시도해 봤다. 양치기. 다행히도 아이펠에 계신 분들은 모두 천사같은 마음씨를 지니셔서... 누군가 솔선수범해서 데이터셋을 공유해주셨다.(나도 데이터를 공유하고 싶었지만 웹캠으로 찍은 사진 상태가 영 좋지 않았다... 다음 번에는 데이터를 나눠줄 수 있는 사람이 되어야지)\n",
    "     \n",
    "     * 우선 데이터셋을 늘려 학습을 진행하기 위해, load_data 함수에 새 인자를 넣어 함수를 조금 고쳐주었다. \n",
    "     매번 numberOfData 변수를 하드코딩해주는 것이 불편했기 때문에 \n",
    "   __loda_data(경로, 학습시킬 이미지 수) 로 함수 일부를 변경하였다.__\n",
    "   \n",
    "     *또, 현재 보유하고 있는 데이터셋은 () 개인데, \n",
    "     1차에는 +()개의 데이터를 추가 학습시켜 정확도 추이를 보고,\n",
    "     2차로 +()개의 데이터를 추가(누적)학습시켜 학습량을 늘리는 것이 정확도 향상에 유의미하게 기여하는지 확인해보려고 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이 실습을 진행하면서 느낀 점\n",
    "\n",
    "## 그 날의 노드는 그 날 하자.\n",
    "    - 사실, 이 노드를 웹에서 진행할 때만 해도 한 번의 오차 없이 결과가 촤라라락! 나왔기 때문에 아주 편안한 마음으로 '음, 주말에 학습 내용을 복습하면서 천천히 하면 되겠군~ ' 이라고 생각했지만, 막상 주피터 노트북에서 시행을 해보니 accuracy 가 계속 1이 나오는 오류가 생겨 주말 내내 이 과제에 매달려 있었다.(예습을 버릴 수 없기에 머리가 터질 것 같을 땐 그냥 다음주 예습을 했다...) \n",
    "    첫 제출이라 정말 완벽하게 보고서를 써 내고 싶었고, 어설프게 완벽주의를 추구하다 보니 과제 수행하는 것을 미루고, 미루고, 미루다가 이런 결과가 나왔는데, 다음 제출부터는 마음은 좀 더 가볍게 먹되 미리 준비해서 이번같은 불상사가 일어나지 않게 해야겠다는 생각이 들었다.\n",
    "    개인적인 감상이지만, 비전공 문과생이라 아예 기초가 없는 개발로 진로를 바꾸다보니 자신감이 부족해져서 '하나를 배울때도 완벽하게 배워서 잘해야 해' 라는 강박이 많이 있었던 것 같다. 다만 아이펠에서는 그런 어설픈 완벽주의로 과제를 미룰 시간조차 주지 않기 때문에(매일매일 예습-복습, 주말에도 예습-복습...) 어쩌면 아이펠에서의 이 시간들이 나에게는 개발자로서의 습관을 들일 좋은 기회라는 생각이 든다.\n",
    "    조금 부족하더라도 일단 해보자. 내 결과물이 맘에 안들어도 일단 해보고 생각하자.\n",
    "    \n",
    "## 그래서 적는 삽질의 연대기\n",
    "    - 민망하기도 하지만, 미래의 내가 보고 반성하라는 의미이기도 하고, 오랜만에 디버깅을 이렇게 새벽까지 붙잡고 있었던 게 신선하고 좋았기 때문에 어떤 삽질 과정을 거쳤는지도 기록해 두고 싶다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원래라면 이렇게 나와야 하는 것 아닌가요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LMS화면](./PostingPic/LMS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 근데 왜 이렇게 나왔죠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![잘못나왔슈](./PostingPic/wrong_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">10번 학습(epoch)시키고, 결과를 확인해보니 전부 1.0이 나왔다.\n",
    "분명히 오류같은데, 왜 그런지 원인을 알 수 없는 상황...\n",
    "오류를 해결하기 위해 stack overflow에 \"sequential 모델의 accuracy가 1.0이야. 뭔가 잘못된걸까?\" 처럼 물어봤더니 \n",
    "어떤 분이 \"음, 너의 사진이 학습하기에 너무 쉬웠나보다!!\" 라고 답변해주었다... 확실히 화요일 당일 진행했던 가위/바위/보 사진 데이터는 너무 지저분하고 역광에서 찍은 것이라 이번에 제출을 위해 처음부터 다시 진행하며, 단일 배경 가위/바위/보 모양으로 바꾼 참이었다. 하지만 LMS 커널에서는 너무나 정상적으로 학습되는 모습을 보여주는데...\n",
    "\n",
    " >* 사진도 바꿔보고\n",
    " >* LMS에서 확인도 해봤지만\n",
    "   \n",
    "> 왜 주피터 노트북에서 따로 진행한 모델만 학습 accuracy가 1.0에 달하는걸까? (심지어 loss 확률도 뒤에 +e가 붙어서 더 오류같다..)\n",
    "일단 다른 분들의 test data set을 가져와서 테스트를 진행해보기로 한다. (여기서도 수치가 1.0에 가깝게 나오면 정말 뭔가 오류가 있는거다!라는 생각으로...)\n",
    "\n",
    "> +슬랙 0-질문있어요 에 올렸더니 퍼실님이 train Set이나 validation set이 너무 작아서 그럴 수 있다고 답변해주셨다.\n",
    "일단 다른 분의 데이터로 테스트하는 과정을 거치고, \n",
    "train셋에 더 많은 데이터들을 넣어서 accuracy가 1.0이 아니라 0.nn대로 나오는 지 확인해보려고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새벽반을 달릴 때 진짜 나는 '아니 코드가 틀린 곳이 없는데 왜 오류가 나와 ㅠㅠ...' 라고 생각하면서 stack overflow를 뒤지고 aiffel slack을\n",
    "마치 강물을 거꾸로 거슬러 오르는 연어처럼(...) 검색하고 있었다.\n",
    "정말 정말 감사하게도, 새벽에 질문을 올렸는데 답글을 달아주신 분들이 계셨고, 또 어떤 분은 예전에 가위바위보 프로젝트를 할 때 수집하셨던\n",
    "데이터까지 보내주시면서 격려를 해 주셨다.. ㅠㅠㅠ(강남 1기 졸업생분 감사합니다..)\n",
    "\n",
    "그리고 위의 답변 중 \"데이터셋이 너무 작거나 너무 판별하기 쉬운 데이터라서 그럴지도 모르니 데이터 양을 늘려보세요!\" 라는 말에 힘입어, \n",
    "기존 데이터(내 데이터셋 300개)에 새 데이터 900개를 더해 작업을 수행했다. 하지만 결과는.... ~똑같았다~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 재시도를 하기 위해 짠 코드와 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다른 사람의 데이터를 가져오려면 파일 이름을 바꿔야지!\n",
    "\n",
    "다른 분들이 협찬해주신 데이터로 추가 학습과 추가 테스트를 진행해보기로 한다.\n",
    "\n",
    "다만 파일 이름의 변경이 필요하여 이름 변경 코드를 좀 짜야 할 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import rename, listdir\n",
    "from PIL import Image\n",
    "\n",
    "#내가 기존에 가지고 있던 내 데이터의 파일 명에 j를 붙이기로 했다 ㅎㅎ\n",
    "#이 코드의 단점 : 약간 수동이다.. 파이썬을 좀 더 잘 다루게 되면 자동화 코드를 다시 만들어보고 싶다.\n",
    "train_image_path=\"/home/ssac23/SUBMIT_MISSION_GIT/ex1_RPC/ModelPic/Paper\"\n",
    "files = glob.glob(train_image_path + '/*.jpg')\n",
    "\n",
    "for file in files:\n",
    "    os.rename(file, os.path.join(train_image_path, 'j'+os.path.basename(file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반자동으로 만든 파이썬 코드를 통해 기존에 가지고 있던 내 파일 이름에 j를 붙여 중복이 발생하지 않도록 한 뒤, 300개의 train데이터를 더 추가해주었다. (총 train data 수 : 각 400 이미지)\n",
    "마찬가지로, test데이터도 위와 같은 방법으로 추가해 주었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 근데 데이터셋을 늘려도 결과는 똑같았답니다. 왜였냐구요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
